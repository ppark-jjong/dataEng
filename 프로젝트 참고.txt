pip install -r requirement.txt
python -m pip install --upgrade pip
python -m venv venv
venv\Scripts\activate
deactivate


import sys
sys.executable

pip install -r requirements.txt
set SPARK_HOME=C:\MyMain\config\venv1\Lib\site-packages\pyspark

set PYSPARK_PYTHON=C:\MyMain\config\venv1\Scripts\python.exe
set PYSPARK_DRIVER_PYTHON=C:\MyMain\config\venv1\Scripts\python.exe


netstat -a -o
taskkill /f /pid PID번호


protoc -I=protos --python_out=protos protos/delivery_status.proto

==================================================================

docker-compose up -d

=============================================================
# Kafka CLI 명령어를 사용하여 토픽 목록 조회
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092

=======
- 토픽 확인법
	컨테이너 내부 진입 만약 잘 안된다면 kafka 설치 경로를 찾아야함
	토픽 검색
	/usr/bin/kafka-topics --bootstrap-server localhost:9092 --delete --topic delivery-data
>>>>>>> origin/main

==================================================================
dashboard
├──.git
├──main/
	├── src/
	│   ├── googleApi.py
	│   ├── producer.py
	│   ├── consumer.py
	│   ├── main.py
	├── proto/
	│   ├── dashboard_status.proto
	│   ├── dashboard_status_pb2.py
	│   ├── monthly_volume_status.proto
	│   ├── monthly_volume_status_pb2.py
	├── docker/
	│   ├── docker-compose.yaml
	├── config/
	│   ├── requirements.txt
	├── oauth/
	│   ├── google/ 
	│   │   ├── credentials.json
└── README.md


1. 실시간 배송 상태 및 KPI 모니터링
목표: 오늘 날짜의 각 배송 상태별 갯수, 완료율, 평균 배송 시간을 모니터링하여 실시간으로 성과를 확인.

2. 이슈 모니터링
목표: 이번 주 동안 발생한 이슈 갯수와 관련된 DPS 번호를 추적.

3. 배송 거리 분석
목표: 이번 주의 평균 배송 거리를 계산하여 분석.

4. 배송 완료율 트렌드 분석
목표: 주별로 배송 완료율의 변화를 분석하여 성과 추적.

5. 이슈 발생 패턴 분석
목표: 요일별 이슈 발생 패턴을 분석하여 빈도 파악.



==================================================================

commons-pool2-2.11.1.jar
kafka-clients-3.4.0.jar
spark-protobuf_2.12-3.4.1.jar
spark-sql-kafka-0-10_2.12-3.4.1.jar
spark-token-provider-kafka-0-10_2.12-3.4.1.jar